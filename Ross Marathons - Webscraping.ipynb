{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Marathons Project: Webscraping & Analysis\n",
    "\n",
    "## This is Part I: I'm going to scrape the marathon data of the past four years and save it to a CSV. Part 2 will include all analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty objects for URLs\n",
    "urlbase_2019 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2019-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2018 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2018-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2017 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2017-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_2016 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Marathon/2016-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2019 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2019-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2018 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2018-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2017 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2017-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n",
    "urlbase_half_2016 = 'https://www.runrocknroll.com/Events/Nashville/The-Races/Half-Marathon/2016-Results?gender=&agegroup=&bib=&firstname=&lastname=&page='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variables for pagination values\n",
    "\n",
    "\n",
    "#For indexing purposes, the range inquiry needs to be 1 higher than the actual value. \n",
    "#So these variables are (actual page count + 1)\n",
    "pages_2016 = 154 + 1\n",
    "pages_2017 = 147 + 1\n",
    "pages_2018 = 85 + 1\n",
    "pages_2019 = 113 + 1\n",
    "pgs_half_2016 = 898 + 1\n",
    "pgs_half_2017 = 892 + 1\n",
    "pgs_half_2018 = 598 + 1\n",
    "pgs_half_2019 = 690 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Marathon Empty DFs\n",
    "\n",
    "marathon2016_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "marathon2017_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "marathon2018_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "marathon2019_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half Marathon Empty DFs\n",
    "\n",
    "half2016_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "half2017_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "half2018_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])\n",
    "half2019_df = pd.DataFrame(columns = ['Overall', 'Bib', 'Name', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marathon_scraper(urlbase, pag_value, df):\n",
    "    for i in range (1, pag_value):\n",
    "        url = urlbase + str(i)\n",
    "        result = requests.post(url)\n",
    "        soup = BeautifulSoup(result.text, 'lxml')\n",
    "        tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "        results_list = pd.read_html(str(tables[0]))\n",
    "        pre_df = pd.DataFrame(results_list[0])\n",
    "        df = pd.concat([df, pre_df], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2019_df = marathon_scraper(urlbase_2019, pages_2019, marathon2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2019_df.to_csv('data/full_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2018_df = marathon_scraper(urlbase_2018, pages_2018, marathon2018_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2018_df.to_csv('data/full_2018.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok I'm gonna try the first for-loop to see what happens. \n",
    "# before adding the concat portion: this gets us a list, but does not append\n",
    "# after adding concat function: if axis=1, we get a weird dataframe with a ton of columns. \n",
    "# I think we're ok with axis=0 - I'll check in with help\n",
    "\n",
    "#Full 2016\n",
    "\n",
    "for i in range (1, pages_2016):\n",
    "    url = urlbase_2016 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    marathon2016_df = pd.concat([marathon2016_df, df], axis=0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30001</td>\n",
       "      <td>Travis Peruski</td>\n",
       "      <td>01:37:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Wietecha</td>\n",
       "      <td>02:34:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Jordan Wilson</td>\n",
       "      <td>02:35:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30034</td>\n",
       "      <td>Steelton Flynn</td>\n",
       "      <td>02:39:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30035</td>\n",
       "      <td>Thomas Ellis</td>\n",
       "      <td>02:42:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Overall    Bib            Name      Time\n",
       "0       1  30001  Travis Peruski  01:37:54\n",
       "1       2      1  Scott Wietecha  02:34:59\n",
       "2       3      4   Jordan Wilson  02:35:24\n",
       "3       4  30034  Steelton Flynn  02:39:59\n",
       "4       5  30035    Thomas Ellis  02:42:09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marathon2019_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2016_df.to_csv('data/full_2016.csv', index = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeautifulSoup\t HTML\t Request\t df\t display\t half2016_df\t half2017_df\t half2018_df\t half2019_df\t \n",
      "i\t marathon2016_df\t marathon2017_df\t marathon2018_df\t marathon2019_df\t marathon_scraper\t pages_2016\t pages_2017\t pages_2018\t \n",
      "pages_2019\t pd\t pgs_half_2016\t pgs_half_2017\t pgs_half_2018\t pgs_half_2019\t requests\t result\t results_list\t \n",
      "soup\t tables\t url\t urlbase_2016\t urlbase_2017\t urlbase_2018\t urlbase_2019\t urlbase_half_2016\t urlbase_half_2017\t \n",
      "urlbase_half_2018\t urlbase_half_2019\t urlopen\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown: I'm just gonna spam this seven more times to get dataframes. Eventually I should work on a function, but let's make sure things pull ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full 2017\n",
    "\n",
    "for i in range (1, pages_2017):\n",
    "    url = urlbase_2017 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    marathon2017_df = pd.concat([marathon2017_df, df], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2017_df.to_csv('data/full_2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full 2018 \n",
    "for i in range (1, pages_2018):\n",
    "    url = urlbase_2018 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    marathon2018_df = pd.concat([marathon2018_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2018_df.to_csv('data/full_2018.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Full 2019 \n",
    "for i in range (1, pages_2019):\n",
    "    url = urlbase_2019 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    marathon2019_df = pd.concat([marathon2019_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon2019_df.to_csv('data/full_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half 2016 \n",
    "for i in range (1, pgs_half_2016):\n",
    "    url = urlbase_half_2016 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    half2016_df = pd.concat([half2016_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "half2016_df.to_csv('data/half_2016.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Half 2017 \n",
    "for i in range (1, pgs_half_2017):\n",
    "    url = urlbase_half_2017 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    half2017_df = pd.concat([half2017_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "half2017_df.to_csv('data/half_2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half 2018 \n",
    "for i in range (1, pgs_half_2018):\n",
    "    url = urlbase_half_2018 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    half2018_df = pd.concat([half2018_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "half2018_df.to_csv('data/half_2018.csv', index = False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14935</td>\n",
       "      <td>8337</td>\n",
       "      <td>Kayleah Maddock</td>\n",
       "      <td>06:04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14937</td>\n",
       "      <td>32614</td>\n",
       "      <td>Kim Donaldson</td>\n",
       "      <td>06:05:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14938</td>\n",
       "      <td>31720</td>\n",
       "      <td>Pamela Samuel Hagens</td>\n",
       "      <td>06:12:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14939</td>\n",
       "      <td>33664</td>\n",
       "      <td>Fatima Rego</td>\n",
       "      <td>06:12:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14940</td>\n",
       "      <td>33532</td>\n",
       "      <td>Annie Friar</td>\n",
       "      <td>06:26:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Overall    Bib                  Name      Time\n",
       "10   14935   8337       Kayleah Maddock  06:04:28\n",
       "11   14937  32614         Kim Donaldson  06:05:35\n",
       "12   14938  31720  Pamela Samuel Hagens  06:12:15\n",
       "13   14939  33664           Fatima Rego  06:12:24\n",
       "14   14940  33532           Annie Friar  06:26:37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half2018_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half 2019 \n",
    "for i in range (1, pgs_half_2019):\n",
    "    url = urlbase_half_2019 + str(i)\n",
    "    result = requests.post(url)\n",
    "    soup = BeautifulSoup(result.text, 'lxml')\n",
    "    tables = soup.find_all('table', attrs = {'class':\"table table-responsive table-bordered\"})\n",
    "    results_list = pd.read_html(str(tables[0]))\n",
    "    df = pd.DataFrame(results_list[0])\n",
    "    half2019_df = pd.concat([half2019_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "half2019_df.to_csv('data/half_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Nick French</td>\n",
       "      <td>01:10:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>Ian Bordelon</td>\n",
       "      <td>01:12:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>Chris Demetra</td>\n",
       "      <td>01:12:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1025</td>\n",
       "      <td>Grayson Reid</td>\n",
       "      <td>01:15:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Jason Vincze</td>\n",
       "      <td>01:17:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Overall   Bib           Name      Time\n",
       "0       1    31    Nick French  01:10:03\n",
       "1       2    33   Ian Bordelon  01:12:15\n",
       "2       3    32  Chris Demetra  01:12:52\n",
       "3       4  1025   Grayson Reid  01:15:10\n",
       "4       5    34   Jason Vincze  01:17:01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half2019_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the end of this notebook. Everything is functional, and I'm going to do my analysis in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
